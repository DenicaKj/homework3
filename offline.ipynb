{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:00:36.981393400Z",
     "start_time": "2024-02-06T00:00:36.876778500Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n",
    "print(\"Spark version:\", spark.version)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-02-06T00:00:46.152737600Z",
     "start_time": "2024-02-06T00:00:36.959789800Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denica\\AppData\\Local\\Temp\\ipykernel_24124\\3765554889.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
      "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
      "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
      "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
      "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
      "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
      "0                   0.0           0.0     0.0  ...            1.0   \n",
      "1                   0.0           1.0     0.0  ...            0.0   \n",
      "2                   0.0           0.0     1.0  ...            1.0   \n",
      "3                   0.0           1.0     1.0  ...            1.0   \n",
      "4                   0.0           1.0     1.0  ...            1.0   \n",
      "\n",
      "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
      "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
      "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
      "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
      "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
      "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
      "\n",
      "   Income  \n",
      "0     3.0  \n",
      "1     1.0  \n",
      "2     8.0  \n",
      "3     6.0  \n",
      "4     4.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Training set shape: (202944, 21) (202944,)\n",
      "Testing set shape: (50736, 21) (50736,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = 'diabetes_binary_health_indicators_BRFSS2015.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "X = data.drop('Diabetes_binary', axis=1)\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "test_size = 0.2  # 80% training, 20% testing\n",
    "random_seed = 42 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:00:53.525183300Z",
     "start_time": "2024-02-06T00:00:49.191967600Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "offline_df = pd.concat([X_train, y_train], axis=1)\n",
    "online_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Save them as CSV files\n",
    "offline_df.to_csv('offline.csv', index=False)\n",
    "online_df.to_csv('online.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:00:58.287641900Z",
     "start_time": "2024-02-06T00:00:53.527181700Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+----+------+------+--------------------+------------+------+-------+-----------------+-------------+-----------+-------+--------+--------+--------+---+----+---------+------+---------------+\n",
      "|HighBP|HighChol|CholCheck| BMI|Smoker|Stroke|HeartDiseaseorAttack|PhysActivity|Fruits|Veggies|HvyAlcoholConsump|AnyHealthcare|NoDocbcCost|GenHlth|MentHlth|PhysHlth|DiffWalk|Sex| Age|Education|Income|Diabetes_binary|\n",
      "+------+--------+---------+----+------+------+--------------------+------------+------+-------+-----------------+-------------+-----------+-------+--------+--------+--------+---+----+---------+------+---------------+\n",
      "|   0.0|     1.0|      1.0|20.0|   1.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              0.0|          1.0|        0.0|    2.0|     0.0|     0.0|     0.0|1.0|12.0|      6.0|   8.0|            0.0|\n",
      "|   0.0|     0.0|      1.0|34.0|   0.0|   0.0|                 0.0|         1.0|   0.0|    1.0|              0.0|          1.0|        0.0|    3.0|     0.0|     0.0|     0.0|1.0| 8.0|      5.0|   8.0|            0.0|\n",
      "|   1.0|     1.0|      1.0|24.0|   0.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              0.0|          1.0|        0.0|    2.0|     0.0|     5.0|     0.0|1.0|12.0|      5.0|   6.0|            1.0|\n",
      "|   0.0|     1.0|      1.0|27.0|   0.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              0.0|          1.0|        0.0|    1.0|     0.0|     0.0|     0.0|1.0| 5.0|      6.0|   7.0|            0.0|\n",
      "|   0.0|     1.0|      1.0|24.0|   0.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              0.0|          1.0|        0.0|    3.0|     0.0|     0.0|     1.0|0.0|12.0|      4.0|   6.0|            0.0|\n",
      "|   1.0|     0.0|      1.0|23.0|   0.0|   0.0|                 0.0|         1.0|   0.0|    1.0|              0.0|          1.0|        0.0|    2.0|     2.0|     3.0|     0.0|0.0| 4.0|      6.0|   8.0|            0.0|\n",
      "|   1.0|     0.0|      1.0|31.0|   0.0|   1.0|                 0.0|         0.0|   0.0|    1.0|              0.0|          1.0|        0.0|    3.0|     2.0|    15.0|     1.0|0.0|13.0|      4.0|   4.0|            0.0|\n",
      "|   1.0|     0.0|      1.0|35.0|   0.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              0.0|          1.0|        0.0|    3.0|     0.0|     0.0|     0.0|1.0| 9.0|      6.0|   7.0|            0.0|\n",
      "|   0.0|     0.0|      1.0|21.0|   0.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              0.0|          1.0|        1.0|    2.0|     0.0|     0.0|     0.0|0.0| 3.0|      6.0|   8.0|            0.0|\n",
      "|   0.0|     0.0|      1.0|29.0|   0.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              0.0|          1.0|        0.0|    1.0|     0.0|     0.0|     0.0|0.0|10.0|      6.0|   7.0|            0.0|\n",
      "|   0.0|     0.0|      1.0|19.0|   0.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              0.0|          1.0|        0.0|    1.0|     5.0|     0.0|     0.0|0.0| 4.0|      6.0|   7.0|            0.0|\n",
      "|   1.0|     1.0|      1.0|30.0|   1.0|   1.0|                 0.0|         0.0|   0.0|    1.0|              0.0|          1.0|        1.0|    4.0|    30.0|     0.0|     1.0|0.0| 7.0|      4.0|   4.0|            1.0|\n",
      "|   1.0|     0.0|      1.0|18.0|   0.0|   0.0|                 0.0|         0.0|   1.0|    1.0|              1.0|          1.0|        0.0|    3.0|     0.0|     0.0|     1.0|0.0|13.0|      6.0|   7.0|            0.0|\n",
      "|   0.0|     1.0|      1.0|29.0|   0.0|   0.0|                 0.0|         1.0|   0.0|    1.0|              0.0|          1.0|        0.0|    1.0|     2.0|     0.0|     0.0|0.0| 9.0|      6.0|   7.0|            0.0|\n",
      "|   0.0|     0.0|      1.0|28.0|   0.0|   0.0|                 0.0|         1.0|   0.0|    1.0|              1.0|          1.0|        0.0|    2.0|     0.0|     0.0|     0.0|1.0| 9.0|      6.0|   8.0|            0.0|\n",
      "|   1.0|     0.0|      1.0|26.0|   0.0|   0.0|                 0.0|         0.0|   1.0|    1.0|              0.0|          1.0|        0.0|    2.0|     0.0|     0.0|     0.0|0.0|13.0|      4.0|   3.0|            0.0|\n",
      "|   1.0|     1.0|      1.0|36.0|   1.0|   0.0|                 0.0|         1.0|   0.0|    1.0|              0.0|          1.0|        0.0|    4.0|     0.0|     3.0|     0.0|1.0| 7.0|      6.0|   8.0|            0.0|\n",
      "|   0.0|     0.0|      1.0|27.0|   1.0|   0.0|                 0.0|         1.0|   1.0|    1.0|              1.0|          1.0|        0.0|    2.0|     0.0|     0.0|     0.0|1.0| 7.0|      6.0|   8.0|            0.0|\n",
      "|   1.0|     0.0|      1.0|30.0|   0.0|   0.0|                 0.0|         0.0|   0.0|    0.0|              0.0|          1.0|        0.0|    3.0|     0.0|     0.0|     0.0|1.0| 7.0|      6.0|   6.0|            0.0|\n",
      "|   1.0|     0.0|      1.0|33.0|   1.0|   0.0|                 1.0|         0.0|   1.0|    1.0|              0.0|          1.0|        0.0|    3.0|     0.0|     0.0|     1.0|1.0|11.0|      4.0|   6.0|            0.0|\n",
      "+------+--------+---------+----+------+------+--------------------+------------+------+-------+-----------------+-------------+-----------+-------+--------+--------+--------+---+----+---------+------+---------------+\n"
     ]
    }
   ],
   "source": [
    "offline_spark_df = spark.read.csv(\"offline.csv\", header=True, inferSchema=True)\n",
    "\n",
    "offline_spark_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:01:09.383867400Z",
     "start_time": "2024-02-06T00:00:58.288649200Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- HighBP: double (nullable = true)\n",
      " |-- HighChol: double (nullable = true)\n",
      " |-- CholCheck: double (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- Smoker: double (nullable = true)\n",
      " |-- Stroke: double (nullable = true)\n",
      " |-- HeartDiseaseorAttack: double (nullable = true)\n",
      " |-- PhysActivity: double (nullable = true)\n",
      " |-- Fruits: double (nullable = true)\n",
      " |-- Veggies: double (nullable = true)\n",
      " |-- HvyAlcoholConsump: double (nullable = true)\n",
      " |-- AnyHealthcare: double (nullable = true)\n",
      " |-- NoDocbcCost: double (nullable = true)\n",
      " |-- GenHlth: double (nullable = true)\n",
      " |-- MentHlth: double (nullable = true)\n",
      " |-- PhysHlth: double (nullable = true)\n",
      " |-- DiffWalk: double (nullable = true)\n",
      " |-- Sex: double (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Education: double (nullable = true)\n",
      " |-- Income: double (nullable = true)\n",
      " |-- Diabetes_binary: double (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "offline_spark_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:01:09.451824500Z",
     "start_time": "2024-02-06T00:01:09.380914800Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score - Logistic Regression: 0.8265798437942979\n",
      "F1 Score - Random Forest: 0.7930987584589925\n",
      "F1 Score - Gradient Boosted Trees: 0.82907661910427\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "label_col = \"Diabetes_binary\"\n",
    "\n",
    "# Assemble features\n",
    "feature_cols = offline_spark_df.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Create classification models\n",
    "lr = LogisticRegression(labelCol=label_col, featuresCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=label_col, featuresCol=\"features\")\n",
    "gbt = GBTClassifier(labelCol=label_col, featuresCol=\"features\")\n",
    "\n",
    "# Create pipelines\n",
    "lr_pipeline = Pipeline(stages=[assembler, lr])\n",
    "rf_pipeline = Pipeline(stages=[assembler, rf])\n",
    "gbt_pipeline = Pipeline(stages=[assembler, gbt])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = offline_spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Set up parameter grids for hyperparameter tuning\n",
    "lr_param_grid = ParamGridBuilder().build()\n",
    "rf_param_grid = ParamGridBuilder().build()\n",
    "gbt_param_grid = ParamGridBuilder().build()\n",
    "\n",
    "# Set up evaluators\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "lr_cv = CrossValidator(estimator=lr_pipeline, estimatorParamMaps=lr_param_grid, evaluator=evaluator, numFolds=5)\n",
    "rf_cv = CrossValidator(estimator=rf_pipeline, estimatorParamMaps=rf_param_grid, evaluator=evaluator, numFolds=5)\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipeline, estimatorParamMaps=gbt_param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Fit models and perform cross-validation\n",
    "lr_model = lr_cv.fit(train_data)\n",
    "rf_model = rf_cv.fit(train_data)\n",
    "gbt_model = gbt_cv.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Evaluate F1 scores\n",
    "lr_f1 = evaluator.evaluate(lr_predictions)\n",
    "rf_f1 = evaluator.evaluate(rf_predictions)\n",
    "gbt_f1 = evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "print(f\"F1 Score - Logistic Regression: {lr_f1}\")\n",
    "print(f\"F1 Score - Random Forest: {rf_f1}\")\n",
    "print(f\"F1 Score - Gradient Boosted Trees: {gbt_f1}\")\n",
    "\n",
    "# Choose the best model based on F1 score\n",
    "best_model = lr_model if lr_f1 > rf_f1 and lr_f1 > gbt_f1 else (rf_model if rf_f1 > gbt_f1 else gbt_model)\n",
    "\n",
    "# Save the best model\n",
    "best_model_path = \"best_model\"\n",
    "best_model.write().overwrite().save(best_model_path)\n",
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:03:53.557572200Z",
     "start_time": "2024-02-06T00:01:09.423271Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e7f4a688",
   "language": "python",
   "display_name": "PyCharm (rnmp1)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
